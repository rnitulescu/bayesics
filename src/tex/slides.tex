%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Slides : Bayes basics ("bayesics") %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% PREAMBLE
%% Define document class and basic options
\documentclass{beamer}
%\setlength{\parindent}{0pt}

%% Load packages
\usepackage{palatino}
\usepackage{amsfonts}
\usepackage{amsmath}
%\usepackage{url}
\usepackage{hyperref}
%\usepackage{listings}
\usepackage{verbatim}
\usepackage[utf8]{inputenc} %% For french
\usepackage{tikz} %% For drawing (eg, Venn diagrams)

\hypersetup{
	colorlinks=true,
	linkcolor=blue,
	citecolor=red,
	filecolor=blue,
	urlcolor=blue
}

\usetheme{Madrid}

%% Basic info
\title{Introduction à la pensé et aux méthodes bayésiennes}
%\subtitle{}
\author{Roy Nitulescu\inst{1}}

\institute
{
    \inst{1}%
    CITADEL\\
    CR-CHUM
}

\date[UdeM, Sept. 22, 2021]{Université de Montréal, Sept. 22, 2021}

\AtBeginSection[]
{
    \begin{frame}
        \frametitle{Table des matières}
        \tableofcontents[currentsection]
    \end{frame}
}

\AtBeginSubsection[]
{
    \begin{frame}
        \frametitle{Table des matières}
        \tableofcontents[currentsubsection]
    \end{frame}
}


%% BEGIN DOCUMENT
\begin{document}

%%%%
%% Slides
%%%%

\frame{\titlepage}

\begin{frame}
    \frametitle{Épigraphe}
    ``La probabilité est le concept le plus important de la science moderne,
    d'autant plus que personne n'a la moindre idée de ce qu'elle signifie.'' -- Bertrand Russell, 1929
\end{frame}


\begin{frame}
    \frametitle{Préambule}
%    \begin{itemize}
%      \item This 3-hour lecture will be broken down into 3 modules
%      \item Each module will last 50 minutes
%      \begin{itemize}
%        \item 30 minutes of lecture time
%        \item 10 minutes for exercises
%        \item 10 minutes for discussing the exercises
%      \end{itemize}
%      \item There will be two 15-minute breaks between the modules
%      \item I expect that all students have already installed R on their computer and tested that it works
%    \end{itemize}
    
%    \vfill
    
    Le code source pour cette présentation ce trouve içi:\\
    \url{https://github.com/rnitulescu/bayesics}
\end{frame}


\begin{frame}
    \frametitle{Table des matières}
    \tableofcontents
\end{frame}


%%%%
%% Motivation
%%%%

\section{Motivation}

\begin{frame}
    \frametitle{La dualité du concept de probabilité}

    De par son origine, le concept à une \textbf{dualité}\footnote{
    Hacking, Ian (1975). \emph{The emergence of probability:
    A philosophical study of early ideas about probability,
    induction and statistical inference}. Cambridge University Press.
    }

    \pause

    \vfill

    \begin{enumerate}
      \item \textbf{Aléatoire}
        \begin{itemize}
          \item Fréquence (la limite d'une fréquence relative dans une séquence infinie)
          \item Propensité (une propriété intrinsèque d'objets ou de situations)
        \end{itemize}

      \pause

      \item \textbf{Épistémique}
        \begin{itemize}
          \item Logique (le degré de soutien ou de confirmation qu'un élément d'évidence confère à une hypothèse donnée)
          \item Subjectif (crédibilité ou degré de croyance subjectif)
        \end{itemize}
    \end{enumerate}    
\end{frame}


\begin{frame}
    \frametitle{Allocation de crédibilité}
    \textbf{L'inférence bayésienne} peut-être résumé ainsi: \pause
    \begin{itemize}
      \item C'est la \textbf{réallocation de crédibilité} parmi toutes les possibilités hypothétiques
            (mutuellement exclusifs et exhaustifs)
      \pause
      \item Les possibilités sont les valeurs potentielles de \textbf{paramétres} dans un modèle mathématique
    \end{itemize}
\end{frame}


\begin{frame}
    \frametitle{Allocation de crédibilité}
    \textbf{Example abstrait:}
    
    \begin{figure}
      \centering
      \includegraphics[scale=0.5]{images/credibility.eps}
      \caption{Allocation et réallocation de crédibilité}
    \end{figure}
\end{frame}


\begin{frame}
    \frametitle{Allocation de crédibilité}
    \textbf{Example concret:\footnote{
      Exemple pris de Kruschke, J. K.(2015). \emph{Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan}.
            Academic Press, pp 20-21.
    }}
    Une usine produit des ballons ronds de différentes tailles (diamètre = 1 dm, 2 dm, 3 dm, ou 4 dm) \pause
    \begin{itemize}
      \item Mais il y a de la variation dans les tailles exactes, en pratique
      \pause
      \item Par example, la taille de chaque ballon suit approximativement une loi normale avec
            taille \textbf{moyenne} de 1, 2, 3, ou 4 dm et \textbf{écart type} de 1.16 dm
      \pause
      \item Supposons que nous avons commandé trois ballons d'une même taille (diamètre = 2 dm),
            mais que nous avons reçu trois ballons avec les tailles suivantes: 1.77, 2.23, et 2.70 dm.
      \pause
      \item Quelle est la probabilité que les trois ballons sont du type avec diamètre = 2 dm?
            Même question pour les autres tailles (1, 3, 4 dm). Finallement, quelle est la
            taille la plus crédible?
    \end{itemize}
\end{frame}


\begin{frame}
    \frametitle{Allocation de crédibilité}
    On reviendra à cet exemple plus tard (vous allez la résoudre comme exercice).

    \pause

    \vfill

    Pour répondre à cette question, nous avons besoin d'un peut de théorie.

    \pause

    \vfill

    Mais avant: une peut d'intuition.
\end{frame}


%%%%
%% Intuition
%%%%

\section{Intuition}

\begin{frame}
    \frametitle{Exemple: diagnostic de maladie\footnote{
        Emprunté et modifié d'un exemple pris dans: Devlin, Keith (2010).
        \emph{The unfinished game: Pascal, Fermat, and the seventeenth-century letter that made the world modern.}
        Basic Books, pp 139-142.
    }}
    Supposons que vous avez reçu un résultat positif pour un test diagnostic d'une maladie rare.
    Quelle est la probabilité que vous avez cette maladie ($\boldsymbol{H}$),
    conditionnellement sur le résultat du test ($\boldsymbol{E}$)?

    \pause

    \vfill

    Voici les faits:
    \begin{itemize}
      \item Prévalence: Parmi \textbf{10,000} individus, \textbf{100} ont la maladie (donc, \textbf{9,900} ne l'ont pas)
      \pause
      \item Sensibilité du test: Parmi les \textbf{100} malades,
            \textbf{95} reçoivent un diagnostic positif (donc, \textbf{5} faux négatifs)
      \pause
      \item Spécificité du test: Parmi les \textbf{9,900} en santé,
            \textbf{7,821} reçoivent un diagnostic négatif (donc, \textbf{2,079} faux positifs)
    \end{itemize}
\end{frame}


\begin{frame}
    \frametitle{Exemple: diagnostic de maladie}
    \begin{figure}
      \centering
      \scalebox{0.75}{\input{content/flow1.tex}}
    \end{figure}

    \pause

    La proportion des patients avec un test positif qui sont véritablement malades est de
    \[\frac{95}{95 + 2079} = 0.044 .\]
\end{frame}


\begin{frame}
    \frametitle{Exemple: diagnostic de maladie (en probabilités)}
    \begin{figure}
      \centering
      \scalebox{0.65}{\input{content/flow2.tex}}
    \end{figure}

    \pause

    Si on suit l'arbre de façon analogique:
    \[p(H | E) = \frac{(0.95)(0.01)}{(0.95)(0.01) + (0.21)(0.99)}\]
    \pause
    \[ = \frac{p(E | H) \, p(H)}{p(E | H) \, p(H) + p(E | H^c) \, p(H^c)} = \frac{p(E | H) \, p(H)}{p(E)}\]
\end{frame}


%%%%
%% Théorie
%%%%

\section{Théorie}

%% Théorie de la probabilité (révision)

\subsection{Théorie de la probabilité (révision)}

\begin{frame}
    \frametitle{Propriétés de la probabilité (négation)}
    \[p(A^c) = 1 - p(A), \,\,\, \textrm{puisque} \,\,\, A \cup A^c = S\]
    \begin{figure}
      \centering
      \scalebox{1}{\input{content/aneg.tex}}
      \caption{Diagramme de Venn représentant la négation (complément)}
    \end{figure}
\end{frame}


\begin{frame}
    \frametitle{Propriétés de la probabilité (Union)\footnote{
        Si $A$ et $B$ sont mutuellement exclusifs, $p(A \cap B) = 0$
    }}
    \[p(A \cup B) = p(A) + p(B) - p(A \cap B)\]
    \begin{figure}
      \centering
      \scalebox{1}{\input{content/aub.tex}}
      \caption{Diagramme de Venn représentant $p(A \cup B)$}
    \end{figure}    
\end{frame}


\begin{frame}
    \frametitle{Probabilité d'intersection et probabilité conditionnelle}
    \[p(A \cap B) = p(A | B) \, p(B) \,\,\, \textrm{Donc,} \,\,\, p(A | B) = \frac{p(A \cap B)}{p(B)}\]

    \begin{figure}
      \centering
      \input{content/anb.tex}
      \caption{Diagramme de Venn représentant $p(A \cap B)$}
    \end{figure}
\end{frame}


\begin{frame}
    \frametitle{Loi de probabilité totale}

    \[p(E) = p(E \cap H) + p(E \cap H^c)\]
    \[ = p(E | H) \, p(H) + p(E | H^c) \, p(H^c)\]

    \begin{figure}
      \centering
      \input{content/totprob.tex}
      \caption{Diagramme de Venn représentant loi de probabilité totale}
    \end{figure}
\end{frame}


%% Théorie bayésienne

\subsection{Théorie bayésienne}

\begin{frame}
    \frametitle{Le théorème de Bayes (probabilités discrètes)}
    Le théorème suit directement de la définition de probabilité conditionnelle:

    \pause

    \[p(A \cap B) =  p(A | B) \, p(B) \,\,\, \pause \textrm{ et } \,\,\, p(B \cap A) =  p(B | A) \, p(A)\]
    \pause
    \[\textrm{Et puisque } \,\,\, p(A \cap B) = p(B \cap A)\]
    \pause
    \[\textrm{Il suit que } \,\,\, p(A | B) \, p(B) = p(B | A) \, p(A)\]
    \pause
    \[\textrm{Donc } \,\,\, p(A | B) = \frac{p(B | A) \, p(A)}{p(B)}\]
    
    Voilà!
\end{frame}


\begin{frame}
    \frametitle{Le théorème de Bayes (probabilités continues)}
    Le théorème suit directement de la définition de la densité conditionnelle:

    \pause

    \[p_{X|Y}(x|y) = \frac{p_{X,Y}(x,y)}{p_Y(y)} \,\,\, \pause \textrm{ et }\]
    \[p_{Y|X}(y|x) = \frac{p_{X,Y}(x,y)}{p_X(x)}\]
    \pause
    \[\textrm{Donc, il suit que } \,\,\, p_{X|Y}(x|y) \, p_Y(y) = p_{Y|X}(y|x) \, p_X(x)\]
    \pause
    \[\textrm{Ce qui implique que } \,\,\, p_{X|Y}(x|y) = \frac{p_{Y|X}(y|x) \, p_X(x)}{p_Y(y)}\]

    Voilà!
\end{frame}


%%%%
%% Applications
%%%%

\section{Applications}

\begin{frame}
    \frametitle{Exemple: mesurer son poids}
    Supposons que vous voulez mesurer votre poids, mais votre balance
    est très imprécise. Comment inférer son poids à partir de plusieurs mesures?

    \pause

    \vfill

    \textbf{Le modèle}

    \[y_i \sim \textrm{N}(\mu, \sigma), \, \, \, i = 1, \ldots, n.\]

    \pause

    \begin{itemize}
      \item On prends $\boldsymbol{n}$ mesures de notre poids, $\boldsymbol{y_i}$
      \pause
      \item Les mesures suivent une loi normale avec moyenne, $\boldsymbol{\mu}$,
            inconnue et écart-type, $\boldsymbol{\sigma}$, connue
      \pause
      \item Disons que $\boldsymbol{n} = 5$, $\boldsymbol{\vec{y}} = (149, 127, 141, 130, 160)$, en livres,
            et $\boldsymbol{\sigma} = 10$
      \pause
      \item Finalement, on émets aussi l'hypothèse que les mesures de poinds sont indépendents
            conditionnellement sur le paramétre, $\boldsymbol{\mu}$
    \end{itemize}
\end{frame}


\begin{frame}
    \frametitle{Exemple: mesurer son poids}
    \textbf{Solution}

    \vfill

    Nous voulons estimer $p(\mu | \vec{y})$

    \pause

    \vfill

    D'après le théorème de Bayes

    \[p(\mu | \vec{y}) = \frac{p(\vec{y} | \mu) \, p(\mu)}{p(\vec{y})} 
      = \frac{p(\vec{y} | \mu) \, p(\mu)}{\int_{-\infty}^{+\infty} p(\vec{y} | \mu) \, p(\mu) \, d\mu}\]
\end{frame}


\begin{frame}[fragile]
    \frametitle{Exemple: mesurer son poids}
    \textbf{Code R}
    \verbatiminput{../R/examples/weight.R}
\end{frame}





%%%%
%% Conclusion
%%%%

\section{Conclusion}

\begin{frame}
    \frametitle{...}
    ...
\end{frame}


\begin{frame}
    \frametitle{Références et lectures suggérées}
    \begin{itemize}
      \item Kruschke, J. K. (2013). Bayesian estimation supersedes the t test.
            \emph{Journal of Experimental Psychology: General}, \emph{142}(2), 573.
      \item Kruschke, J. K., \& Vanpaemel, W. (2015). Bayesian estimation in hierarchical models.
            \emph{The Oxford handbook of computational and mathematical psychology, 279}.
      \item Kruschke, J. K.(2015). \emph{Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan}.
            Academic Press.
      \item Gelman, A., Carlin, J. B., Stern, H. S., \& Rubin, D. B. (1995).
            \emph{Bayesian data analysis}. Chapman and Hall/CRC.
    \end{itemize}
\end{frame}


%% END DOCUMENT
\end{document}

